{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download dataset and unzip file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only download if file does not exist yet:\n",
    "if not os.path.exists('LD2011_2014.txt'):\n",
    "    # Define URL\n",
    "    URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip\"\n",
    "    # Download the file from `URL` and save it locally under `file_name`:\n",
    "    urllib.request.urlretrieve(URL, \"LD2011_2014.txt.zip\")\n",
    "    # Unzip file:\n",
    "    zip_ref = zipfile.ZipFile(\"LD2011_2014.txt.zip\", 'r')\n",
    "    zip_ref.extractall()\n",
    "    zip_ref.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140256 entries, 0 to 140255\n",
      "Columns: 371 entries, Unnamed: 0 to MT_370\n",
      "dtypes: float64(370), object(1)\n",
      "memory usage: 397.0+ MB\n",
      "None\n",
      "            Unnamed: 0  MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  \\\n",
      "0  2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1  2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2  2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3  2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4  2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_007  MT_008  MT_009  ...  MT_361  MT_362  MT_363  MT_364  MT_365  \\\n",
      "0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_366  MT_367  MT_368  MT_369  MT_370  \n",
      "0     0.0     0.0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "# open raw file downloaded to local machine:\n",
    "raw_file_path = 'LD2011_2014.txt'\n",
    "\n",
    "# use raw file to read csv and get raw dataframe:\n",
    "raw_dataset = pd.read_csv(raw_file_path, delimiter=';', header=0, decimal=',', index_col=False, low_memory=False)\n",
    "\n",
    "# check dataframe info and head:\n",
    "print(raw_dataset.info())\n",
    "print(raw_dataset.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rename column containing dates' in string format and convert it to datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime     object\n",
      "MT_001      float64\n",
      "MT_002      float64\n",
      "MT_003      float64\n",
      "MT_004      float64\n",
      "             ...   \n",
      "MT_366      float64\n",
      "MT_367      float64\n",
      "MT_368      float64\n",
      "MT_369      float64\n",
      "MT_370      float64\n",
      "Length: 371, dtype: object\n",
      "float64           370\n",
      "datetime64[ns]      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# since column with datetime values doesn't have name, rename it to 'datetime':\n",
    "data_timecol = raw_dataset.rename(columns={'Unnamed: 0':'datetime'})\n",
    "\n",
    "# check dtypes for dataframe before converstion of 'datetime' column to datetime dtype:\n",
    "print(data_timecol.dtypes)\n",
    "\n",
    "# transform rennamed column into datetime dtype:\n",
    "data_timecol['datetime'] = pd.to_datetime(data_timecol['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# check if conversion was successful:\n",
    "print(data_timecol.dtypes.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resample data from 15min frequency to hourly frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35065\n",
      "             datetime  MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
      "0 2011-01-01 00:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1 2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2 2011-01-01 02:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3 2011-01-01 03:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4 2011-01-01 04:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_008  MT_009  ...  MT_361  MT_362  MT_363  MT_364  MT_365  MT_366  \\\n",
      "0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_367  MT_368  MT_369  MT_370  \n",
      "0     0.0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "# resample data from 15min level to hourly level:\n",
    "data_resamp = data_timecol.resample('1H', on='datetime').sum().reset_index()\n",
    "\n",
    "# get length of data_resamp:\n",
    "data_resamp_length = len(data_resamp)\n",
    "\n",
    "# check to see if resampling went through:\n",
    "print(data_resamp.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to get tidy dataframe, use melt to pivot dataframe and get it vertically stacked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime  client_id  KwH\n",
      "0 2011-01-01 00:00:00          1  0.0\n",
      "1 2011-01-01 01:00:00          1  0.0\n",
      "2 2011-01-01 02:00:00          1  0.0\n",
      "3 2011-01-01 03:00:00          1  0.0\n",
      "4 2011-01-01 04:00:00          1  0.0\n"
     ]
    }
   ],
   "source": [
    "resampled_data = data_resamp\n",
    "\n",
    "# stack dataset by melting it (the value_name col will be recalculated after):\n",
    "melted_data = pd.melt(resampled_data, id_vars=['datetime'], var_name='client_id', value_name='KwH')\n",
    "\n",
    "# Remove 'MT_' from client_id col:\n",
    "melted_data['client_id'] = melted_data['client_id'].str.replace('MT_', '').astype(int)\n",
    "print(melted_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For client data that started late and ended early, get first and last nonzero dates for each client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>client_id</th>\n",
       "      <th>KwH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  client_id  KwH\n",
       "0 2011-01-01 00:00:00          1  0.0\n",
       "1 2011-01-01 01:00:00          1  0.0\n",
       "2 2011-01-01 02:00:00          1  0.0\n",
       "3 2011-01-01 03:00:00          1  0.0\n",
       "4 2011-01-01 04:00:00          1  0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_dates = melted_data[melted_data['KwH'] != 0].groupby('client_id', as_index=False).agg(\n",
    "    min=('datetime','min'),\n",
    "    max=('datetime','max')\n",
    "    )\n",
    "\n",
    "cutoff_dates.tail()\n",
    "melted_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if client presents empty rows at the start or the end of the dataframe, get rid of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>client_id</th>\n",
       "      <th>KwH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>12.690355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>16.497462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>2012-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>19.035533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2012-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.766497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2012-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>19.035533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  client_id        KwH\n",
       "8760 2012-01-01 00:00:00          1  12.690355\n",
       "8761 2012-01-01 01:00:00          1  16.497462\n",
       "8762 2012-01-01 02:00:00          1  19.035533\n",
       "8763 2012-01-01 03:00:00          1  17.766497\n",
       "8764 2012-01-01 04:00:00          1  19.035533"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = melted_data.copy()\n",
    "\n",
    "def filter_rows_before_after_date(df, cutoff_dates):\n",
    "    df = df.merge(cutoff_dates, on='client_id', how='left')\n",
    "    df['is_before_start'] = df['datetime'] < df['min']\n",
    "    df['is_after_end'] = df['datetime'] > df['max']\n",
    "    df.drop(df[df.is_before_start == True].index, inplace=True)\n",
    "    df.drop(df[df.is_after_end == True].index, inplace=True)\n",
    "    df.drop(['is_before_start', 'is_after_end', 'min', 'max'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "melted_data = filter_rows_before_after_date(melted_data, cutoff_dates)\n",
    "melted_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# round 'KwH' values to 2 decimals and check for zero values that would not be registered as NaN originally because of near-zero instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id\n",
      "132    19073\n",
      "131    15653\n",
      "347    15638\n",
      "130    14213\n",
      "348    12189\n",
      "15      2640\n",
      "66      2339\n",
      "133     1945\n",
      "127     1065\n",
      "288      523\n",
      "3        149\n",
      "123       50\n",
      "1         38\n",
      "340       38\n",
      "57        32\n",
      "143       32\n",
      "346       31\n",
      "370       30\n",
      "336       29\n",
      "151       28\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hard_zero_counts = melted_data[melted_data['KwH'] == 0].groupby('client_id').size().sort_values(ascending=False)\n",
    "\n",
    "print(hard_zero_counts.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "           zero_counts  client_counts  zero_counts_ratio\n",
      "client_id                                               \n",
      "347            15638.0          25981              60.19\n",
      "132            19073.0          35065              54.39\n",
      "130            14213.0          26305              54.03\n",
      "348            12189.0          26304              46.34\n",
      "131            15653.0          35065              44.64\n",
      "133             1945.0           7041              27.62\n",
      "15              2640.0          13811              19.12\n",
      "66              2339.0          26305               8.89\n",
      "127             1065.0          21937               4.85\n",
      "288              523.0          35065               1.49\n",
      "3                149.0          26305               0.57\n",
      "178               23.0           4009               0.57\n",
      "181               23.0           7249               0.32\n",
      "337               23.0           8377               0.27\n",
      "179               23.0           9049               0.25\n",
      "123               50.0          26305               0.19\n",
      "370               30.0          17521               0.17\n",
      "340               38.0          26305               0.14\n",
      "1                 38.0          26305               0.14\n",
      "143               32.0          26305               0.12\n"
     ]
    }
   ],
   "source": [
    "# create new column 'KwH_round' round and round values to 2 decimals:\n",
    "melted_data['KwH_round'] = melted_data['KwH'].round(2)\n",
    "\n",
    "# check size of zero values in KwH_round column for each client_id:\n",
    "zero_counts = melted_data[melted_data['KwH_round'] == 0].groupby('client_id').size()\n",
    "\n",
    "# drop KwH_round column:\n",
    "melted_data.drop('KwH_round', axis=1, inplace=True)\n",
    "\n",
    "# sort values in descending order:\n",
    "zero_counts = zero_counts.sort_values(ascending=False)\n",
    "\n",
    "# get number of observations for each client_id:\n",
    "client_counts = melted_data.groupby('client_id').size()\n",
    "\n",
    "# combine zero_counts and client_counts into zero_counts_df:\n",
    "zero_counts_df = pd.DataFrame({'zero_counts': zero_counts, 'client_counts': client_counts})\n",
    "\n",
    "# create new column 'zero_counts_ratio' and calculate ratio of zero_counts to client_counts:\n",
    "zero_counts_df['zero_counts_ratio'] = (zero_counts_df['zero_counts'] * 100 / zero_counts_df['client_counts']).round(2)\n",
    "\n",
    "# sort values in descending order:\n",
    "zero_counts_df = zero_counts_df.sort_values(by='zero_counts_ratio', ascending=False)\n",
    "\n",
    "# check zero_counts_df:\n",
    "print(zero_counts_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                datetime  client_id        KwH  mov_avg_24h\n",
      "8760 2012-01-01 00:00:00          1  12.690355          NaN\n",
      "8761 2012-01-01 01:00:00          1  16.497462          NaN\n",
      "8762 2012-01-01 02:00:00          1  19.035533          NaN\n",
      "8763 2012-01-01 03:00:00          1  17.766497          NaN\n",
      "8764 2012-01-01 04:00:00          1  19.035533          NaN\n",
      "8765 2012-01-01 05:00:00          1  17.766497          NaN\n",
      "8766 2012-01-01 06:00:00          1  17.766497          NaN\n",
      "8767 2012-01-01 07:00:00          1  17.766497          NaN\n",
      "8768 2012-01-01 08:00:00          1  11.421320          NaN\n",
      "8769 2012-01-01 09:00:00          1   8.883249          NaN\n"
     ]
    }
   ],
   "source": [
    "# if 'mov_avg_24h' doesn't exist, create rolling window of 24 hours:\n",
    "if 'mov_avg_24h' not in melted_data.columns:\n",
    "    melted_data['mov_avg_24h'] = melted_data.groupby('client_id')['KwH'].rolling(24).mean().reset_index(0,drop=True)\n",
    "\n",
    "# check data:\n",
    "print(melted_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                datetime  client_id        KwH  mov_avg_24h\n",
      "8760 2012-01-01 00:00:00          1  12.690355          NaN\n",
      "8761 2012-01-01 01:00:00          1  16.497462          NaN\n",
      "8762 2012-01-01 02:00:00          1  19.035533          NaN\n",
      "8763 2012-01-01 03:00:00          1  17.766497          NaN\n",
      "8764 2012-01-01 04:00:00          1  19.035533          NaN\n",
      "8765 2012-01-01 05:00:00          1  17.766497          NaN\n",
      "8766 2012-01-01 06:00:00          1  17.766497          NaN\n",
      "8767 2012-01-01 07:00:00          1  17.766497          NaN\n",
      "8768 2012-01-01 08:00:00          1  11.421320          NaN\n",
      "8769 2012-01-01 09:00:00          1   8.883249          NaN\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
